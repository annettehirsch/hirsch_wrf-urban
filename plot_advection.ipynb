{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!/usr/bin/env python\n",
    "\"\"\"plot_advection.py\n",
    "\n",
    "Script plots contour maps of the heat and moisture advection\n",
    "d02: 800m resolution with urban LCZs\n",
    "\n",
    "Author: Annette L Hirsch @ CLEX, UNSW. Sydney (Australia)\n",
    "email: a.hirsch@unsw.edu.au\n",
    "Created: Tue Sep  8 09:10:48 AEST 2020\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import netCDF4 as nc\n",
    "import sys\n",
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import xarray as xr\n",
    "from matplotlib import cm\n",
    "from matplotlib.collections import LineCollection\n",
    "import common_functions as cf\n",
    "import datetime as dt\n",
    "import wrf\n",
    "from scipy import stats\n",
    "import metpy.calc as mpcalc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Details of the Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Period\n",
    "syear = 2017\n",
    "smon = 1\n",
    "sday = 2 \n",
    "eyear = 2017\n",
    "emon = 2\n",
    "eday = 28  # Add an extra day so that the 27th Feb data is included\n",
    "simlen = dt.datetime(eyear,emon,eday) - dt.datetime(syear,smon,sday)\n",
    "nst = (simlen.days * 24 * 6) # No. simulations days x 24 hours in a day x 6 history intervals per hour\n",
    "\n",
    "# Dates - Used for subsetting the AWS data so you pick the day before the start date and the day after the end date\n",
    "sdate = \"2017-01-01\"\n",
    "edate = \"2017-02-28\"\n",
    "\n",
    "# Data directory \n",
    "datadir='/g/data/w97/azh561/WRF/'\n",
    "ensmem = ['sydney800m','sydney800m_06H','sydney800m_12H','sydney800m_18H','sydney800m_00H'] \n",
    "domain = [\"d02\",\"d02\",\"d02\",\"d02\",\"d02\"]\n",
    "nmem = len(ensmem)\n",
    "\n",
    "# Landsea mask\n",
    "mask_file='/g/data/w97/azh561/WRF/sydney800m/geo_em.%s.nc' %(domain[0])\n",
    "f = nc.Dataset(mask_file)\n",
    "lu = f.variables['LU_INDEX'][0,:,:]\n",
    "luf = f.variables['LANDUSEF'][0,:,:,:]\n",
    "lat2d = f.variables['XLAT_M'][0,:,:]\n",
    "lontmp = f.variables['XLONG_M'][0,:,:]\n",
    "lon2d = np.where(lontmp<0.0,lontmp+360,lontmp)\n",
    "hgt2d = f.variables['HGT_M'][0,:,:]\n",
    "lsmask = f.variables['LANDMASK'][0,:,:]\n",
    "clon = f.getncattr('CEN_LON')\n",
    "nlu = f.getncattr('NUM_LAND_CAT')\n",
    "iswater = f.getncattr('ISWATER')\n",
    "nlat,nlon = lon2d.shape\n",
    "f.close()\n",
    "\n",
    "\n",
    "lat1d = lat2d[:,0]\n",
    "lon1d = lon2d[0,:]\n",
    "# Use helper function defined above to calculate distance\n",
    "# between lat/lon grid points\n",
    "dx, dy = mpcalc.lat_lon_grid_deltas(lon1d, lat1d)\n",
    "# Because of the way the data are returned we need a negative spacing. This\n",
    "# will be easier in the next version of MetPy.\n",
    "dy *= -1\n",
    "\n",
    "nlev = 44\n",
    "\n",
    "# LCZs\n",
    "LCZnm = ['Compact high-rise','Compact midrise','Compact low-rise','Open high-rise',\n",
    "         'Open low-rise','Lightweight low-rise','Large low-rise','Sparsely built','Heavy industry']\n",
    "\n",
    "# Figure Details\n",
    "fig_dir='%s/figures/' %(os.getcwd())\n",
    "fig_name_prefix='LCZ_'\n",
    "if not os.path.exists(fig_dir):\n",
    "  os.makedirs(fig_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(syear,smon,sday,0,0,0)\n",
    "end = dt.datetime(eyear,emon,eday,0,0,0)\n",
    "days = (end - start).days\n",
    "ntim = days * 24 * 60\n",
    "datelist = [start + dt.timedelta(minutes=x) for x in range(ntim+1)]\n",
    "# Get the day-month hour-minutes on 10 minute interval\n",
    "ftimes = np.asarray([datelist[x].strftime(\"%m-%d %H-%M\") for x in range(ntim+1)])[::10]\n",
    "fhours = np.asarray([datelist[x].strftime(\"%H\") for x in range(ntim+1)])[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split analysis by heatwave periods\n",
    "\n",
    "From the Bureau of Meteorology Special Climate Statement 61 there were 3 heatwaves:\n",
    "\n",
    "    10-14 January\n",
    "    17-21 January\n",
    "    31 January - 12 February \n",
    "    \n",
    "For the latter heatwave this was terminated by a cold front.\n",
    "\n",
    "So here we examine separately the week before the first heatwave, each heatwave period and the week after the third heatwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRES = [i for i in range(len(ftimes)) if ftimes[i] in ['01-03 00-00']][0]\n",
    "PREF = [i for i in range(len(ftimes)) if ftimes[i] in ['01-10 00-00']][0]\n",
    "\n",
    "HW1S = [i for i in range(len(ftimes)) if ftimes[i] in ['01-10 00-00']][0]\n",
    "HW1F = [i for i in range(len(ftimes)) if ftimes[i] in ['01-15 00-00']][0]\n",
    "\n",
    "HW2S = [i for i in range(len(ftimes)) if ftimes[i] in ['01-17 00-00']][0]\n",
    "HW2F = [i for i in range(len(ftimes)) if ftimes[i] in ['01-22 00-00']][0]\n",
    "\n",
    "HW3S = [i for i in range(len(ftimes)) if ftimes[i] in ['01-31 00-00']][0]\n",
    "HW3F = [i for i in range(len(ftimes)) if ftimes[i] in ['02-13 00-00']][0]\n",
    "\n",
    "POSTS = [i for i in range(len(ftimes)) if ftimes[i] in ['02-13 00-00']][0]\n",
    "POSTF = [i for i in range(len(ftimes)) if ftimes[i] in ['02-20 00-00']][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = sorted(glob.glob('%s/%s/WRF_output/%s/wrfout_%s_2017-*' %(datadir,ensmem[1],domain[1],domain[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-01-02'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[0][65:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract model data corresponding to an East-West Transect through the city (latitude index of 174)\n",
    "\n",
    "- run this on gadi to avoid memory limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mm in range(nmem):\n",
    "    \n",
    "    # Files list\n",
    "    filelist = sorted(glob.glob('%s/%s/WRF_output/%s/wrfout_%s_2017-*' %(datadir,ensmem[mm],domain[mm],domain[mm])))\n",
    "    nfile = len(filelist)\n",
    "    for ff in range(int(nfile/24)):\n",
    "\n",
    "        ta = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        qv = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        ua = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        va = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        adv = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        mt = np.empty((144,nlat,nlon),dtype=np.float64)\n",
    "        \n",
    "        wrffiles = [nc.Dataset(filelist[(ff*24)]),nc.Dataset(filelist[(ff*24)+1]),nc.Dataset(filelist[(ff*24)+2])\n",
    "        ,nc.Dataset(filelist[(ff*24)+3]),nc.Dataset(filelist[(ff*24)+4]),nc.Dataset(filelist[(ff*24)+5])\n",
    "        ,nc.Dataset(filelist[(ff*24)+6]),nc.Dataset(filelist[(ff*24)+7]),nc.Dataset(filelist[(ff*24)+8])\n",
    "        ,nc.Dataset(filelist[(ff*24)+9]),nc.Dataset(filelist[(ff*24)+10]),nc.Dataset(filelist[(ff*24)+11])\n",
    "        ,nc.Dataset(filelist[(ff*24)+12]),nc.Dataset(filelist[(ff*24)+13]),nc.Dataset(filelist[(ff*24)+14])\n",
    "        ,nc.Dataset(filelist[(ff*24)+15]),nc.Dataset(filelist[(ff*24)+16]),nc.Dataset(filelist[(ff*24)+17])\n",
    "        ,nc.Dataset(filelist[(ff*24)+18]),nc.Dataset(filelist[(ff*24)+19]),nc.Dataset(filelist[(ff*24)+20])\n",
    "        ,nc.Dataset(filelist[(ff*24)+21]),nc.Dataset(filelist[(ff*24)+22]),nc.Dataset(filelist[(ff*24)+23])]\n",
    "\n",
    "        pres = wrf.getvar(wrffiles,\"pressure\",timeidx=None,method='cat')[:144,:,:,:]\n",
    "        temp = wrf.getvar(wrffiles,\"tk\",timeidx=None,method='cat')[:144,:,:,:]\n",
    "        qvap = wrf.getvar(wrffiles,\"QVAPOR\",timeidx=None,method='cat')[:144,:,:,:]\n",
    "        uwnd = wrf.getvar(wrffiles,\"ua\",timeidx=None,method='cat')[:144,:,:,:]\n",
    "        vwnd = wrf.getvar(wrffiles,\"va\",timeidx=None,method='cat')[:144,:,:,:]\n",
    "        t2 = wrf.getvar(wrffiles,\"T2\",timeidx=None,method='cat')[:144,:,:] - 273.15\n",
    "         \n",
    "        # Extract variables at desired level\n",
    "        ta = wrf.to_np(wrf.interplevel(temp,pres,850.))\n",
    "        qv = wrf.to_np(wrf.interplevel(qvap,pres,850.))\n",
    "        ua = wrf.to_np(wrf.interplevel(uwnd,pres,850.))\n",
    "        va = wrf.to_np(wrf.interplevel(vwnd,pres,850.))\n",
    "        \n",
    "        del pres,temp,qvap,uwnd,vwnd,wwnd\n",
    "        \n",
    "        # Calculate the advection\n",
    "        for tind in range(144):\n",
    "            adv[tind,:,:] = mpcalc.advection(ta[tind,:,:], [ua[tind,:,:], va[tind,:,:]],(dx, dy), dim_order='yx')\n",
    "            mt[tind,:,:] = mpcalc.advection(qv[tind,:,:], [ua[tind,:,:], va[tind,:,:]],(dx, dy), dim_order='yx')\n",
    "            \n",
    "        for a in range(24):\n",
    "            wrffiles[a].close()\n",
    "        \n",
    "        # Create 1 file per day\n",
    "        dataset = nc.Dataset('/g/data/w97/azh561/WRF/processed/wrfout_850hPa_%s_%s_%s.nc' %(filelist[ff*24][61:71],ensmem[mm],domain[mm]),'w') # open file\n",
    "\n",
    "        # Create dimensions\n",
    "        time = dataset.createDimension('time',None)\n",
    "        lat = dataset.createDimension('lat',nlat)\n",
    "        lon = dataset.createDimension('lon',nlon)\n",
    "\n",
    "        # Create coordinate variables\n",
    "        times = dataset.createVariable('time',ftimes.dtype,('time',))\n",
    "        latitude = dataset.createVariable('lat',np.float64,('lat','lon',))\n",
    "        longitude = dataset.createVariable('lon',np.float64,('lat','lon',))\n",
    "\n",
    "        # Create variables\n",
    "        ADV850 = dataset.createVariable('ADV850', np.float64,('time','lat','lon'))\n",
    "        MT850 = dataset.createVariable('MT850', np.float64,('time','lat','lon'))\n",
    "        T2M = dataset.createVariable('T2M', np.float64,('time','lat','lon'))\n",
    "\n",
    "        # Write data\n",
    "        ADV850[:] = adv[:] \n",
    "        MT850[:] = mt[:] \n",
    "        T2M[:] = t2[:] \n",
    "        times[:] = ftimes[144*ff:144*(ff+1)]\n",
    "        latitude[:] = lat2d\n",
    "        longitude[:] = lon2d\n",
    "\n",
    "        # Write the file\n",
    "        dataset.close()\n",
    "\n",
    "        del ta,qv,ua,va,adv,mt,t2    \n",
    "        \n",
    "    del filelist,nfile\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the extracted data and plot\n",
    "- calculate the ensemble average on Gadi using ncea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get urban\n",
    "file = nc.Dataset('/g/data/w97/azh561/WRF/processed/wrfout_850hPa_%s.nc' %('d02'),'r')\n",
    "ADV = file.variables['ADV'][:,:,:]\n",
    "MT = file.variables['MT'][:,:,:]\n",
    "file.close()\n",
    "\n",
    "# Extract particular timesteps where the Blue Mountains advection or sea breeze \n",
    "# is active leading in/out of a heatwave"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
