{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!/usr/bin/env python\n",
    "\"\"\"plot_urban_vs_grass.py\n",
    "\n",
    "Script plots the point time series of the model data between the two nested domains:\n",
    "d02: 800m resolution with urban LCZs\n",
    "d03: 800m resolution where all urban areas are replaced with grass\n",
    "\n",
    "Author: Annette L Hirsch @ CLEX, UNSW. Sydney (Australia)\n",
    "email: a.hirsch@unsw.edu.au\n",
    "Created: Thu Jul 30 14:26:12 AEST 2020\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import netCDF4 as nc\n",
    "import sys\n",
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import xarray as xr\n",
    "from matplotlib.collections import LineCollection\n",
    "import common_functions as cf\n",
    "import datetime as dt\n",
    "import wrf\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Period\n",
    "syear = 2017\n",
    "smon = 1\n",
    "sday = 2 \n",
    "eyear = 2017\n",
    "emon = 2\n",
    "eday = 28  # Add an extra day so that the 27th Feb data is included\n",
    "simlen = dt.datetime(eyear,emon,eday) - dt.datetime(syear,smon,sday)\n",
    "nst = (simlen.days * 24 * 6) # No. simulations days x 24 hours in a day x 6 history intervals per hour\n",
    "\n",
    "# Dates - Used for subsetting the AWS data so you pick the day before the start date and the day after the end date\n",
    "sdate = \"2017-01-01\"\n",
    "edate = \"2017-02-28\"\n",
    "\n",
    "# Data directory \n",
    "datadir='/g/data/w97/azh561/WRF/'\n",
    "ensmem = ['sydney800m','sydney800m','sydney800m_06H','sydney800m_06H','sydney800m_12H','sydney800m_12H','sydney800m_18H','sydney800m_18H','sydney800m_00H','sydney800m_00H'] \n",
    "rlabels = ['U1','G1','U2','G2','U3','G3','U4','G4','U5','G5']\n",
    "domain = [\"d02\",\"d03\",\"d02\",\"d03\",\"d02\",\"d03\",\"d02\",\"d03\",\"d02\",\"d03\"]\n",
    "nmem = len(ensmem)\n",
    "\n",
    "# Landsea mask\n",
    "mask_file='/g/data/w97/azh561/WRF/sydney800m/geo_em.%s.nc' %(domain[0])\n",
    "f = nc.Dataset(mask_file)\n",
    "lu = f.variables['LU_INDEX'][0,:,:]\n",
    "lat2d = f.variables['XLAT_M'][0,:,:]\n",
    "lontmp = f.variables['XLONG_M'][0,:,:]\n",
    "lon2d = np.where(lontmp<0.0,lontmp+360,lontmp)\n",
    "clon = f.getncattr('CEN_LON')\n",
    "nlu = f.getncattr('NUM_LAND_CAT')\n",
    "iswater = f.getncattr('ISWATER')\n",
    "f.close()\n",
    "\n",
    "# Figure Details\n",
    "fig_dir='%s/figures/' %(os.getcwd())\n",
    "fig_name_prefix='AWS_comparison_'\n",
    "if not os.path.exists(fig_dir):\n",
    "  os.makedirs(fig_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Data - start by comparing at AWS locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awsdir = '/g/data/w97/azh561/WRF/obs/AWS_1mindata_20stations'\n",
    "awsnum = ['066037','066137','066194','067105','067108','067113','061078','061366','066062','067119','068228']\n",
    "awsnm = ['Sydney Airport','Bankstown Airport','Canterbury Racecourse','Richmond RAAF','Badgerys Creek','Penrith Lakes','Williamtown RAAF','Norah Head','Sydney Observatory Hill','Horsley Park','Bellambi']\n",
    "awslat = [-33.9465,-33.9176,-33.9057,-33.6004,-33.8969,-33.7195,-32.7939,-33.2814,-33.8607,-33.851,-34.3691]\n",
    "awslon = [151.1731,150.9837,151.1134,150.7761,150.7281,150.6783,151.8364,151.5766,151.2050,150.8567,150.9291]\n",
    "naws = len(awsnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to note the bad quality observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_values(data):\n",
    "    \n",
    "    # https://stackoverflow.com/questions/19909167/how-to-find-most-frequent-string-element-in-numpy-ndarray\n",
    "    unique,pos = np.unique(data,return_inverse=True)\n",
    "    counts = np.bincount(pos)\n",
    "    maxpos = counts.argmax() # To find the positions of the max count\n",
    "    \n",
    "    if unique[maxpos] in ['Y'] and counts[maxpos] == 10:\n",
    "        qcflag = np.nan\n",
    "    else:\n",
    "        qcflag = 0.05\n",
    "        \n",
    "    return qcflag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the 10 minute average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_10min_avg(dataframe):\n",
    "    \n",
    "    # Variables of interest\n",
    "    otc = dataframe['tc']\n",
    "    orh = dataframe['rh']\n",
    "    odp = dataframe['dp']\n",
    "    omslp = dataframe['mslp']\n",
    "    opr = dataframe['pr']\n",
    "    owspd = dataframe['wspd']\n",
    "    owdir = dataframe['wdir']\n",
    "\n",
    "    # Quality control flags\n",
    "    otc_qc = dataframe['tc_qc']\n",
    "    orh_qc = dataframe['rh_qc']\n",
    "    odp_qc = dataframe['dp_qc']\n",
    "    omslp_qc = dataframe['mslp_qc']\n",
    "    opr_qc = dataframe['pr_qc']\n",
    "    owspd_qc = dataframe['wspd_qc']\n",
    "    owdir_qc = dataframe['wdir_qc']    \n",
    "\n",
    "    # Calculate the 10-minute averages - NOT THE MOST EFFICIENT WAY I'M SURE OF IT!\n",
    "    odata = np.empty((7,nst),dtype=np.float64)\n",
    "    oqc = np.empty((7,nst),dtype=np.float64)\n",
    "    for tt in range(nst):\n",
    "\n",
    "        # MSLP\n",
    "        odata[0,tt] = np.mean([float(omslp.iloc[(tt*10)]),float(omslp.iloc[(tt*10)+1]),float(omslp.iloc[(tt*10)+2]),\n",
    "             float(omslp.iloc[(tt*10)+3]),float(omslp.iloc[(tt*10)+4]),float(omslp.iloc[(tt*10)+5]),\n",
    "             float(omslp.iloc[(tt*10)+6]),float(omslp.iloc[(tt*10)+7]),float(omslp.iloc[(tt*10)+8]),\n",
    "             float(omslp.iloc[(tt*10)+9])])\n",
    "        # T2\n",
    "        odata[1,tt] = np.mean([float(otc.iloc[(tt*10)]),float(otc.iloc[(tt*10)+1]),float(otc.iloc[(tt*10)+2]),\n",
    "             float(otc.iloc[(tt*10)+3]),float(otc.iloc[(tt*10)+4]),float(otc.iloc[(tt*10)+5]),\n",
    "             float(otc.iloc[(tt*10)+6]),float(otc.iloc[(tt*10)+7]),float(otc.iloc[(tt*10)+8]),\n",
    "             float(otc.iloc[(tt*10)+9])])\n",
    "        # TD2\n",
    "        odata[2,tt] = np.mean([float(odp.iloc[(tt*10)]),float(odp.iloc[(tt*10)+1]),float(odp.iloc[(tt*10)+2]),\n",
    "             float(odp.iloc[(tt*10)+3]),float(odp.iloc[(tt*10)+4]),float(odp.iloc[(tt*10)+5]),\n",
    "             float(odp.iloc[(tt*10)+6]),float(odp.iloc[(tt*10)+7]),float(odp.iloc[(tt*10)+8]),\n",
    "             float(odp.iloc[(tt*10)+9])])\n",
    "        # RH2\n",
    "        odata[3,tt] = np.mean([float(orh.iloc[(tt*10)]),float(orh.iloc[(tt*10)+1]),float(orh.iloc[(tt*10)+2]),\n",
    "             float(orh.iloc[(tt*10)+3]),float(orh.iloc[(tt*10)+4]),float(orh.iloc[(tt*10)+5]),\n",
    "             float(orh.iloc[(tt*10)+6]),float(orh.iloc[(tt*10)+7]),float(orh.iloc[(tt*10)+8]),\n",
    "             float(orh.iloc[(tt*10)+9])])\n",
    "        # PR - total rather than mean\n",
    "        odata[4,tt] = np.sum([float(opr.iloc[(tt*10)]),float(opr.iloc[(tt*10)+1]),float(opr.iloc[(tt*10)+2]),\n",
    "             float(opr.iloc[(tt*10)+3]),float(opr.iloc[(tt*10)+4]),float(opr.iloc[(tt*10)+5]),\n",
    "             float(opr.iloc[(tt*10)+6]),float(opr.iloc[(tt*10)+7]),float(opr.iloc[(tt*10)+8]),\n",
    "             float(opr.iloc[(tt*10)+9])])\n",
    "        # Wind Speed\n",
    "        odata[5,tt] = np.mean([float(owspd.iloc[(tt*10)]),float(owspd.iloc[(tt*10)+1]),float(owspd.iloc[(tt*10)+2]),\n",
    "             float(owspd.iloc[(tt*10)+3]),float(owspd.iloc[(tt*10)+4]),float(owspd.iloc[(tt*10)+5]),\n",
    "             float(owspd.iloc[(tt*10)+6]),float(owspd.iloc[(tt*10)+7]),float(owspd.iloc[(tt*10)+8]),\n",
    "             float(owspd.iloc[(tt*10)+9])])\n",
    "        # Wind Dir\n",
    "        odata[6,tt] = np.mean([float(owdir.iloc[(tt*10)]),float(owdir.iloc[(tt*10)+1]),float(owdir.iloc[(tt*10)+2]),\n",
    "             float(owdir.iloc[(tt*10)+3]),float(owdir.iloc[(tt*10)+4]),float(owdir.iloc[(tt*10)+5]),\n",
    "             float(owdir.iloc[(tt*10)+6]),float(owdir.iloc[(tt*10)+7]),float(owdir.iloc[(tt*10)+8]),\n",
    "             float(owdir.iloc[(tt*10)+9])])\n",
    "\n",
    "        ### Get the instances where the data quality is bad\n",
    "        oqc[0,tt] = get_bad_values([omslp_qc.iloc[(tt*10)],omslp_qc.iloc[(tt*10)+1],omslp_qc.iloc[(tt*10)+2],\n",
    "             omslp_qc.iloc[(tt*10)+3],omslp_qc.iloc[(tt*10)+4],omslp_qc.iloc[(tt*10)+5],\n",
    "             omslp_qc.iloc[(tt*10)+6],omslp_qc.iloc[(tt*10)+7],omslp_qc.iloc[(tt*10)+8],\n",
    "             omslp_qc.iloc[(tt*10)+9]])\n",
    "        oqc[1,tt] = get_bad_values([otc_qc.iloc[(tt*10)],otc_qc.iloc[(tt*10)+1],otc_qc.iloc[(tt*10)+2],\n",
    "             otc_qc.iloc[(tt*10)+3],otc_qc.iloc[(tt*10)+4],otc_qc.iloc[(tt*10)+5],\n",
    "             otc_qc.iloc[(tt*10)+6],otc_qc.iloc[(tt*10)+7],otc_qc.iloc[(tt*10)+8],\n",
    "             otc_qc.iloc[(tt*10)+9]])\n",
    "        oqc[2,tt] = get_bad_values([odp_qc.iloc[(tt*10)],odp_qc.iloc[(tt*10)+1],odp_qc.iloc[(tt*10)+2],\n",
    "             odp_qc.iloc[(tt*10)+3],odp_qc.iloc[(tt*10)+4],odp_qc.iloc[(tt*10)+5],\n",
    "             odp_qc.iloc[(tt*10)+6],odp_qc.iloc[(tt*10)+7],odp_qc.iloc[(tt*10)+8],\n",
    "             odp_qc.iloc[(tt*10)+9]])\n",
    "        oqc[3,tt] = get_bad_values([orh_qc.iloc[(tt*10)],orh_qc.iloc[(tt*10)+1],orh_qc.iloc[(tt*10)+2],\n",
    "             orh_qc.iloc[(tt*10)+3],orh_qc.iloc[(tt*10)+4],orh_qc.iloc[(tt*10)+5],\n",
    "             orh_qc.iloc[(tt*10)+6],orh_qc.iloc[(tt*10)+7],orh_qc.iloc[(tt*10)+8],\n",
    "             orh_qc.iloc[(tt*10)+9]])\n",
    "        oqc[4,tt] = get_bad_values([opr_qc.iloc[(tt*10)],opr_qc.iloc[(tt*10)+1],opr_qc.iloc[(tt*10)+2],\n",
    "             opr_qc.iloc[(tt*10)+3],opr_qc.iloc[(tt*10)+4],opr_qc.iloc[(tt*10)+5],\n",
    "             opr_qc.iloc[(tt*10)+6],opr_qc.iloc[(tt*10)+7],opr_qc.iloc[(tt*10)+8],\n",
    "             opr_qc.iloc[(tt*10)+9]])\n",
    "        oqc[5,tt] = get_bad_values([owspd_qc.iloc[(tt*10)],owspd_qc.iloc[(tt*10)+1],owspd_qc.iloc[(tt*10)+2],\n",
    "             owspd_qc.iloc[(tt*10)+3],owspd_qc.iloc[(tt*10)+4],owspd_qc.iloc[(tt*10)+5],\n",
    "             owspd_qc.iloc[(tt*10)+6],owspd_qc.iloc[(tt*10)+7],owspd_qc.iloc[(tt*10)+8],\n",
    "             owspd_qc.iloc[(tt*10)+9]])\n",
    "        oqc[6,tt] = get_bad_values([owdir_qc.iloc[(tt*10)],owdir_qc.iloc[(tt*10)+1],owdir_qc.iloc[(tt*10)+2],\n",
    "             owdir_qc.iloc[(tt*10)+3],owdir_qc.iloc[(tt*10)+4],owdir_qc.iloc[(tt*10)+5],\n",
    "             owdir_qc.iloc[(tt*10)+6],owdir_qc.iloc[(tt*10)+7],owdir_qc.iloc[(tt*10)+8],\n",
    "             owdir_qc.iloc[(tt*10)+9]])\n",
    "\n",
    "    return odata,oqc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and calculate the 10-minute averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata = np.empty((naws,7,nst),dtype=np.float64)\n",
    "oqc = np.empty((naws,7,nst),dtype=np.float64)\n",
    "for ss in range(naws):\n",
    "    \n",
    "    # Read data\n",
    "    file = \"%s/HD01D_Data_%s_46163679534753.txt\" %(awsdir,awsnum[ss])\n",
    "    data = pd.read_csv(file)\n",
    "    # MUST USE THE UTC TIME SO THAT WRF AND AWS DATA TIMES ARE THE SAME\n",
    "    data.columns = [\"a\",\"No\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"year\",\"month\",\"day\",\"hour\",\"minute\",\n",
    "                \"pr\",\"pr_qc\",\"l\",\"tc\",\"tc_qc\",\"wbt\",\"wbt_qc\",\"dp\",\"dp_qc\",\"rh\",\"rh_qc\",\"vp\",\"vp_qc\",\n",
    "                \"svp\",\"svp_qc\",\"wspd\",\"wspd_qc\",\"wdir\",\"wdir_qc\",\"m\",\"n\",\"o\",\"p\",\"vis\",\"vis_qc\",\"mslp\",\"mslp_qc\",\"q\"]\n",
    "\n",
    "    data['date'] = pd.to_datetime(data[['year','month','day']])\n",
    "    data['time'] = pd.to_datetime(data[['year','month','day','hour','minute']])\n",
    "\n",
    "    # Clip to period of interest\n",
    "    date_filter = data.loc[(data['date'] > sdate) & (data['date'] < edate)]\n",
    "\n",
    "    # Deal with empty cells\n",
    "    date_filter = date_filter.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Calculate the 10 minute averages\n",
    "    odata[ss,:,:],oqc[ss,:,:] = calc_10min_avg(date_filter)\n",
    "    \n",
    "    del data,date_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Model data closest to the stations - Iterate through groups of files \n",
    "    takes 40 mins per ensemble member for the 2 months of simulation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slat = np.empty(naws,dtype=int)\n",
    "slon = np.empty(naws,dtype=int)\n",
    "for ss in range(naws):\n",
    "    \n",
    "    # Get lat/lon corresponding to the AWS site\n",
    "    # https://stackoverflow.com/questions/28006077/find-i-j-location-of-closest-long-lat-values-in-a-2d-array\n",
    "    a = abs(lat2d-awslat[ss])+abs(lon2d-awslon[ss])\n",
    "    i0,j0 = np.unravel_index(a.argmin(),a.shape)\n",
    "\n",
    "    slat[ss] = i0\n",
    "    slon[ss] = j0\n",
    "    \n",
    "    del a,i0,j0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mm in range(nmem):\n",
    "\n",
    "    # Files list\n",
    "    filelist = sorted(glob.glob('%s/%s/WRF_output/%s/wrfout_%s_2017-*' %(datadir,ensmem[mm],domain[mm],domain[mm])))\n",
    "    nfile = len(filelist)\n",
    "\n",
    "    #for ff in range(simlen.days):\n",
    "    for ff in range(int(nfile/24)):\n",
    "\n",
    "        wrffiles = [nc.Dataset(filelist[(ff*24)]),nc.Dataset(filelist[(ff*24)+1]),nc.Dataset(filelist[(ff*24)+2])\n",
    "        ,nc.Dataset(filelist[(ff*24)+3]),nc.Dataset(filelist[(ff*24)+4]),nc.Dataset(filelist[(ff*24)+5])\n",
    "        ,nc.Dataset(filelist[(ff*24)+6]),nc.Dataset(filelist[(ff*24)+7]),nc.Dataset(filelist[(ff*24)+8])\n",
    "        ,nc.Dataset(filelist[(ff*24)+9]),nc.Dataset(filelist[(ff*24)+10]),nc.Dataset(filelist[(ff*24)+11])\n",
    "        ,nc.Dataset(filelist[(ff*24)+12]),nc.Dataset(filelist[(ff*24)+13]),nc.Dataset(filelist[(ff*24)+14])\n",
    "        ,nc.Dataset(filelist[(ff*24)+15]),nc.Dataset(filelist[(ff*24)+16]),nc.Dataset(filelist[(ff*24)+17])\n",
    "        ,nc.Dataset(filelist[(ff*24)+18]),nc.Dataset(filelist[(ff*24)+19]),nc.Dataset(filelist[(ff*24)+20])\n",
    "        ,nc.Dataset(filelist[(ff*24)+21]),nc.Dataset(filelist[(ff*24)+22]),nc.Dataset(filelist[(ff*24)+23])]\n",
    "\n",
    "        # Extract the variables of interest\n",
    "        timetmp  = wrf.getvar(wrffiles,\"times\",timeidx=None,method='cat')               # Times\n",
    "        rh2tmp   = wrf.getvar(wrffiles,\"rh2\",timeidx=None,method='cat')[:,slat,slon]                         # 2m Relative Humidity\n",
    "        td2tmp   = wrf.getvar(wrffiles,\"td2\",units='degC',timeidx=None,method='cat')[:,slat,slon]            # 2m Dew Point Temperature\n",
    "        t2tmp    = wrf.getvar(wrffiles,'T2',timeidx=None,method='cat')[:,slat,slon] - 273.15                               # 2m temperature\n",
    "        psfctmp  = wrf.getvar(wrffiles,'PSFC',timeidx=None,method='cat')[:,slat,slon] /100.                                # surface pressure hPa\n",
    "        prtmp    = wrf.getvar(wrffiles,'RAINC',timeidx=None,method='cat')[:,slat,slon] + wrf.getvar(wrffiles,'RAINNC',timeidx=None,method='cat')[:,slat,slon] # total precipitation mm\n",
    "        windtmp  = wrf.getvar(wrffiles,\"wspd_wdir10\",units='km h-1',timeidx=None,method='cat')[:,:,slat,slon] # 10m wind speed and direction\n",
    "\n",
    "        # Append to arrays\n",
    "        if ff == 0:\n",
    "            ftimes = timetmp\n",
    "            rh2 = rh2tmp\n",
    "            td2 = td2tmp\n",
    "            t2 = t2tmp\n",
    "            psfc = psfctmp\n",
    "            pr = prtmp\n",
    "            wspd = windtmp[0,:,:,:]\n",
    "            wdir = windtmp[1,:,:,:]\n",
    "        else:\n",
    "            ftimes = np.append(ftimes,timetmp,axis=0)\n",
    "            rh2 = np.append(rh2,rh2tmp,axis=0)\n",
    "            td2 = np.append(td2,td2tmp,axis=0)\n",
    "            t2 = np.append(t2,t2tmp,axis=0)\n",
    "            psfc = np.append(psfc,psfctmp,axis=0)\n",
    "            pr = np.append(pr,prtmp,axis=0)\n",
    "            wspd = np.append(wspd,windtmp[0,:,:,:],axis=0)\n",
    "            wdir = np.append(wdir,windtmp[1,:,:,:],axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        del timetmp,rh2tmp,td2tmp,t2tmp,psfctmp,prtmp,windtmp\n",
    "\n",
    "    ftimes = ftimes.astype('datetime64[m]')\n",
    "\n",
    "    if mm == 0:\n",
    "        tsdata = np.empty((naws,nmem,7,len(ftimes)),dtype=np.float64) # [nmem+1,nvar,ntime]\n",
    "        times = ftimes\n",
    "\n",
    "    for ss in range(naws):\n",
    "        tsdata[ss,mm,0,:len(ftimes)] = psfc[:len(ftimes),ss,ss]\n",
    "        tsdata[ss,mm,1,:len(ftimes)] = t2[:len(ftimes),ss,ss]\n",
    "        tsdata[ss,mm,2,:len(ftimes)] = td2[:len(ftimes),ss,ss]\n",
    "        tsdata[ss,mm,3,:len(ftimes)] = rh2[:len(ftimes),ss,ss]\n",
    "        tsdata[ss,mm,4,:len(ftimes)] = 0.0 # First set all pr values to zero\n",
    "        for tt in range(len(pr)-1):\n",
    "            tsdata[ss,mm,4,tt] = pr[tt+1,ss,ss] - pr[tt,ss,ss]\n",
    "        tsdata[ss,mm,5,:len(ftimes)] = wspd[:len(ftimes),ss,ss]\n",
    "        tsdata[ss,mm,6,:len(ftimes)] = wdir[:len(ftimes),ss,ss]\n",
    "\n",
    "    # Once data read for an ensemble member - write to file - saves read time later!\n",
    "    for ss in range(naws):\n",
    "        datadump = np.vstack([tsdata[ss,mm,0,:len(ftimes)], tsdata[ss,mm,1,:len(ftimes)], tsdata[ss,mm,2,:len(ftimes)],\n",
    "         tsdata[ss,mm,3,:len(ftimes)], tsdata[ss,mm,4,:len(ftimes)], tsdata[ss,mm,5,:len(ftimes)],\n",
    "            tsdata[ss,mm,6,:len(ftimes)]])\n",
    "        np.savetxt('WRF_output_M%s_%s_AWS%s.txt' %(ensmem[mm],domain,awsnum[ss]), (datadump.T), delimiter = ' ',header = \"PSFC T2 TD2 RH2 PR WSPD WDIR\", fmt = '%0.4f %0.4f %0.4f %0.4f %0.4f %0.4f %0.4f')\n",
    "        del datadump\n",
    "    \n",
    "        \n",
    "    del psfc,t2,td2,rh2,pr,wspd,wdir,filelist,nfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in previously extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(syear,smon,sday,0,0,0)\n",
    "end = dt.datetime(eyear,emon,eday,0,0,0)\n",
    "days = (end - start).days\n",
    "ntim = days * 24 * 60\n",
    "datelist = [start + dt.timedelta(minutes=x) for x in range(ntim+1)]\n",
    "# Get the day-month hour-minutes on 10 minute interval\n",
    "ftimes = np.asarray([datelist[x].strftime(\"%m-%d %H-%M\") for x in range(ntim+1)])[::10]\n",
    "fdates = np.asarray([datelist[x].strftime(\"%m-%d\") for x in range(ntim+1)])[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdata = np.empty((naws,nmem,7,len(ftimes)),dtype=np.float64)\n",
    "# Loop through the ensemble members\n",
    "for mm in range(nmem):\n",
    "\n",
    "    # Loop through the sites\n",
    "    for ss in range(naws):\n",
    "    \n",
    "        # Read data\n",
    "        data = pd.read_csv('WRFOUT_AWS_EXTRACTED_GRIDS/WRF_output_M%s_%s_AWS%s.txt' %(ensmem[mm],domain[mm],awsnum[ss]),delimiter = ' ')\n",
    "        data.columns = [\"PSFC\", \"T2\", \"TD2\", \"RH2\", \"PR\", \"WSPD\", \"WDIR\",\"#\"]\n",
    "    \n",
    "        tsdata[ss,mm,0,:] = data['PSFC'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,1,:] = data['T2'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,2,:] = data['TD2'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,3,:] = data['RH2'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,4,:] = data['PR'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,5,:] = data['WSPD'].iloc[0:len(ftimes)]\n",
    "        tsdata[ss,mm,6,:] = data['WDIR'].iloc[0:len(ftimes)]\n",
    "    \n",
    "        del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "def plot_ts(time,tsdata,rlabels,vlabels,mtitle,figurename,lspace):\n",
    "\n",
    "    \"\"\"This function plots time series for observations and models\"\"\"\n",
    "\n",
    "    from matplotlib.colors import BoundaryNorm\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    import string\n",
    "    \n",
    "    # Figure formatting\n",
    "    plt.rcParams['savefig.dpi']=300\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "\n",
    "    # Define dimensions\n",
    "    nmod = tsdata.shape[0]\n",
    "    nvar = tsdata.shape[1]\n",
    "    nt = tsdata.shape[2]\n",
    "\n",
    "    # Create figure object and subplots\n",
    "    fig, ax = plt.subplots(nvar, 1, figsize=(30.0,5.0*(nvar)), squeeze=False)\n",
    "    tarr = np.arange(0,nt)\n",
    "    \n",
    "    colors = [\"red\",\"blue\",\"grey\",\"orange\",\"purple\"] \n",
    "    ca = [0,0,1,1,2,2,3,3,4,4]\n",
    "    \n",
    "    # Iterate through variables\n",
    "    for vind in range(nvar):\n",
    "\n",
    "        # Models\n",
    "        for mind in np.arange(0,nmod,2):\n",
    "            llabel = '%s minus %s' %(rlabels[mind],rlabels[mind+1])\n",
    "            ax[vind,0].plot(tarr,(tsdata[mind,vind,:]-tsdata[mind+1,vind,:]), linewidth=2,color=colors[ca[mind]], \n",
    "                            linestyle='-', label=llabel)\n",
    "\n",
    "        # Fix Labelling\n",
    "        ax[vind,0].set_ylabel('%s' %(vlabels[vind]), fontweight = 'bold',fontsize=20)\n",
    "        ax[vind,0].axhline(0, color='grey', linestyle='--',linewidth=2.0)\n",
    " \n",
    "        # Amend axis limits\n",
    "        ax[vind,0].set_xlim(tarr[0],tarr[-1])\n",
    "        \n",
    "        if vind < nvar-1:\n",
    "            ax[vind,0].set_xticks([],[])\n",
    "        else:\n",
    "            ax[vind,0].set_xticks(tarr[::lspace])\n",
    "            ax[vind,0].set_xticklabels(time[::lspace],rotation=90,fontsize=18)\n",
    "\n",
    "    ax[0,0].set_title(mtitle, fontweight = 'bold',fontsize=20)\n",
    "    legend = ax[-1,0].legend(loc='upper center', bbox_to_anchor=(0.5,-0.275), ncol=6, fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.savefig(figurename,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlabels = ['MSLP [hPa]','$T_{2m}$ [\\xb0 C]','$T_{dp}$ [\\xb0 C]', 'RH [%]','PR [mm]','WSPD [$km.hr^{-1}$]','WDIR [\\xb0]']\n",
    "lspace = 144 # As the wrf output is saved at a 10 minute interval\n",
    "\n",
    "for ss in range(naws):\n",
    "    figurename = 'Urban_vs_Grass_%s.png' %(awsnm[ss])\n",
    "    plot_ts(fdates[:],tsdata[ss,:,:,:],rlabels,vlabels,awsnm[ss],figurename,lspace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the KDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "def plot_kde(mdata,odata,rlabels,vlabels,figurename,pflag=True):\n",
    "    \"\"\"This function plots separate panels for each model \n",
    "    \"\"\"\n",
    "    import seaborn as sns; sns.set(style=\"white\", color_codes=True)\n",
    "\n",
    "    # Define dimensions\n",
    "    nmod = mdata.shape[0]\n",
    "    nvar = mdata.shape[1]\n",
    "    npts = mdata.shape[2]\n",
    "      \n",
    "    # Create figure object and subplots\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(15,10), squeeze=False)\n",
    "    \n",
    "    plt.rcParams['savefig.dpi'] = 300\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.titlepad\"] = -12.0\n",
    "    \n",
    "    # Define the line styles and colors for the datasets\n",
    "    mycolors=['red','red','blue','blue','grey','grey',\"orange\",\"orange\",\"purple\",\"purple\"]\n",
    "    mylines=['-','--','-','--','-','--','-','--','-','--']\n",
    "    ypos = [0.95,0.9,0.85,0.8,0.75,0.7]\n",
    "    r = [0,0,0,1,1,1]\n",
    "    c = [0,1,2,0,1,2]\n",
    "     \n",
    "    # Loop through the variables\n",
    "    for vv in range(nvar):        \n",
    "        \n",
    "\n",
    "            # Loop through the model\n",
    "            for mm in range(nmod):\n",
    "                sns.kdeplot(mdata[mm,vv,:], ax=ax[r[vv],c[vv]], shade=False, color=mycolors[mm], linestyle=mylines[mm],linewidth=2,label=rlabels[mm],legend=False)\n",
    "                # Add p-value \n",
    "                if pflag == True:\n",
    "                    _, pks = stats.ks_2samp(mdata[mm,vv,:],odata[mm,:])\n",
    "                    ax[r[vv],c[vv]].text(0.1,ypos[mm],'p = %s' %(round(pks,4)),\n",
    "                            horizontalalignment='center',verticalalignment='center',transform = ax[r[vv],c[vv]].transAxes,\n",
    "                            color=mycolors[mm], fontweight='bold')\n",
    "                    del pks\n",
    "\n",
    "            # Add the obs\n",
    "            sns.kdeplot(odata[vv,:], ax=ax[r[vv],c[vv]], shade=False, color='black', linestyle=mylines[0],linewidth=3,label='AWS',legend=False)\n",
    "\n",
    "                    \n",
    "            # Labelling of subplot panels\n",
    "            ax[r[vv],c[vv]].set_xlabel('%s' %(vlabels[vv]), fontweight = 'bold')\n",
    "            ax[r[vv],c[vv]].set_ylabel(\"Density Function\")\n",
    "\n",
    "    legend = ax[-1,1].legend(loc='upper center', bbox_to_anchor=(0.5,-0.15), ncol=6, fontsize=14)\n",
    "    fig.subplots_adjust(wspace=0.30, hspace=0.25)\n",
    "    fig.savefig(figurename,bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlabels = ['MSLP [hPa]','$T_{2m}$ [\\xb0 C]','$T_{dp}$ [\\xb0 C]', 'RH [%]','PR [mm]','WSPD [$km.hr^{-1}$]','WDIR [\\xb0]']\n",
    "\n",
    "for ss in range(naws):\n",
    "    figurename = 'KDE_%s.png' %(awsnm[ss])\n",
    "    plot_kde(tsdata[ss,:,1:,:],odata[ss,1:,:],rlabels,vlabels[1:],figurename,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
